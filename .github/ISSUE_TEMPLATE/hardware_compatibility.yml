name: Hardware Compatibility Report
description: Report compatibility issues or success with specific hardware configurations
title: "[HARDWARE] "
labels: ["hardware-compatibility", "triage"]
body:
  - type: markdown
    attributes:
      value: |
        Help us improve hardware compatibility by reporting your experience!
        This information helps other users know what to expect with different hardware.

  - type: dropdown
    id: report-type
    attributes:
      label: Report Type
      description: Are you reporting a problem or a success?
      options:
        - Success - Working configuration
        - Problem - Not working or limited functionality
        - Performance - Works but with issues
    validations:
      required: true

  - type: textarea
    id: hardware
    attributes:
      label: Hardware Configuration
      description: Detailed information about your hardware
      placeholder: |
        - GPU: NVIDIA RTX 4060 Ti 16GB
        - CPU: AMD Ryzen 9 5900X
        - RAM: 32GB DDR4
        - Storage: 1TB NVMe SSD
        - Motherboard: (if relevant)
        - Power Supply: (if relevant for GPU issues)
    validations:
      required: true

  - type: textarea
    id: software
    attributes:
      label: Software Configuration
      description: Software environment details
      placeholder: |
        - OS: Ubuntu 24.04 LTS
        - CUDA version: 12.8
        - Python version: 3.12
        - PyTorch version: 2.5.1
        - Earth2Studio version: 0.12.0-fork.1
        - Driver version: 565.57.01
    validations:
      required: true

  - type: checkboxes
    id: models-tested
    attributes:
      label: Models Tested
      description: Which models did you test?
      options:
        - label: FourCastNet (FCN)
        - label: FourCastNet3 (FCN3)
        - label: GraphCast Small
        - label: GraphCast Operational
        - label: AIFS
        - label: AIFS Ensemble
        - label: Pangu
        - label: FuXi
        - label: Aurora
        - label: Atlas
        - label: Other (specify in details)

  - type: dropdown
    id: precision
    attributes:
      label: Precision Used
      description: What precision did you use?
      options:
        - FP32 (Full Precision)
        - FP16 (Half Precision)
        - Mixed Precision
        - INT8 (Quantized)
        - Other
    validations:
      required: true

  - type: textarea
    id: memory-usage
    attributes:
      label: Memory Usage
      description: GPU memory consumption observed
      placeholder: |
        Model: GraphCast Operational
        Precision: FP16
        Peak GPU Memory: 14.2 GB
        Average GPU Memory: 12.8 GB
        Was memory sufficient? Yes/No

  - type: textarea
    id: performance
    attributes:
      label: Performance Metrics
      description: Performance measurements if available
      placeholder: |
        - Inference time per step: 2.5 seconds
        - Throughput: 0.4 steps/second
        - Model loading time: 15 seconds
        - Batch size used: 1
        - Any performance issues: ...

  - type: textarea
    id: optimizations
    attributes:
      label: Optimizations Applied
      description: What optimizations did you use?
      placeholder: |
        - FP16 conversion: Yes
        - Gradient checkpointing: No
        - Reduced batch size: Yes (1)
        - Other: torch.backends.cudnn.benchmark = True

  - type: dropdown
    id: success-level
    attributes:
      label: Overall Success Level
      description: How would you rate the overall experience?
      options:
        - "5 - Works perfectly, no issues"
        - "4 - Works well with minor optimizations"
        - "3 - Works with significant optimizations"
        - "2 - Partially works, major limitations"
        - "1 - Does not work"
    validations:
      required: true

  - type: textarea
    id: issues
    attributes:
      label: Issues Encountered
      description: Describe any problems you encountered
      placeholder: |
        - Out of memory errors (resolved with FP16)
        - Slow inference (acceptable for use case)
        - Installation problems with Flash Attention
        - ...

  - type: textarea
    id: recommendations
    attributes:
      label: Recommendations
      description: Your recommendations for others with similar hardware
      placeholder: |
        - This GPU works well for GraphCast Small in FP16
        - Need at least 20GB VRAM for GraphCast Operational even in FP16
        - Flash Attention compilation takes 2 hours
        - ...

  - type: textarea
    id: additional
    attributes:
      label: Additional Information
      description: Any other relevant information
      placeholder: Screenshots, logs, benchmark results, etc.
